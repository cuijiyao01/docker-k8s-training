# Trainer Guide

## Overview

#### Course Prep steps
These are the logical steps for a trainer to prep for a course (details below):
- Create a Gardener trial cluster for your training
- Download your trainer .kube/config from Gardener that lets you control the cluster
- On your VM, run the script to generate the kube configs for the participants
- Copy the generated configs to the config share of this course
- Print the access IDs sheet to be handed out to the participants (with their config IDs)

All artifacts / scripts / info needed as trainer is in this admin folder.
You can use the participant VM also for all work as a trainer.

## Course preparation

Contact the K8s training organization team to ge Gardner Cluster for the training.

~~### Create a Gardener Trial Cluster for the training

~~For each training we are using a separate **trial cluster** that you get from [Gardener](https://github.wdf.sap.corp/pages/kubernetes/gardener/).

~~**TODO: description HOWTO**

~~**TODO: describe how to get the kubeconfig for the seed cluster. The config allows you to edit the shoot cluster's yaml file as long as it is not possible via the Gardener UI.**

### Download your trainer .kube/config

In Gardener
- Login to gardener (with SSO via 'Test the self-service')
- Choose your cluster
- in `kube cluster access` pane, click on on Kubeconfig and copy the yaml

On your VM / machine
- Create a directory `.kube` under HOME (e.g. /home/vagrant on VM) and cd into it
- Create new file `config` and paste the yaml
- run `kubectl get nodes` - this command must complete by giving you a short list of nodes in the cluster

### Generate the kube configs for the participants

Download or clone this repo into the VM / your linux machine.

CD into `./docker-k8s-training/admin/kubecfggen` and there do `chmod 755 kubecfggen.sh`.

Now run the script `kubecfggen.sh`. Give it the number of participants/namespaces it should create (e.g. `kubecfggen.sh 10` creates 10 different namespaces for 10 participants).
- It creates a new directory with a new training ID `training-xxxxxxxx` (8 char ID) where all generated files will be.
- Generates a yaml to create all namespaces etc in the cluster and already execute / apply it. The cluster will then already be set up for the participants.
- Generates the kubeconfig files for the participants in the subdir for the training
- Packages all files for this training into a tar.

**Please note, the script creates not only the namespaces. It also deploys a ResourceQuota & LimitRange to each namespace.**
With this abuse of the training cluster should become harder. The ResourceQuota limits the number of pods accepted by each namespace to 15. Any particpant trying to scale a deployment to a hundred pods or more will not harm other participants. The LimitRange assigns default values for memory and CPU requested by a pod. It also give a default limit. If a pod does not specify any of these it will inherit the defaults. In other terms, by specifying a cpu/memory request & limit, the defaults can be overwritten.

### Copy the configs to the share

Upload the tar file using this Jenkins job: https://cc-admin.mo.sap.corp/view/K8s/job/upload-k8s-training-namespaces/

Participants will download 'their config' using the trainings and participant ID.


### Print the participant config codes sheet

Print the file that was generated by the `kubecfggen` run that contains the trainings ID and config codes for each participant. Cut the page at the lines so that you can hand out each code to one participant.

## Setup you up for the training

### Fork the training repo and clone it
Fork the central [training repo](https://github.wdf.sap.corp/slvi/docker-k8s-training) into your account or organization and continue to work from there. This way you will be able to adapt the training to your needs & environment.

Clone your forked repo to your VM. There are demo scripts/files for the container, docker and kubernetes parts.

### Check the ingress URLs
Gardener deploys an ingress controller to each cluster and allows you to register custom URLs to a specific subdomain. Since the subdomain contains the name of the Gardener project as well as the cluster, you have to adapt the ingress resources to match with your setup. Changes are neccessary to the [sock-shop](../kubernetes/solutions/sock-shop.yaml) and [ingress](../kubernetes/solutions/ingress.yaml) files.

The URL pattern looks like this: `[custom-endpoint].ingress.[cluster-name].[project-name].shoot.canary.k8s-hana.ondemand.com`

### Check IP address ranges
Most likely, the Gardener cluster runs on SAP external infrastructure like AWS or GCP. To make our setup a bit more secure, we would recommend to limit access to whatever you expose in the cluster to traffic originating from a SAP network.
Check the internal [network inforamation portal](https://nip.wdf.sap.corp/nip2/faces/networking/wan/PublicAddresses.xhtml), to figure out the address ranges of the training locations. Configure firewall rules in your respective IaaS account to block traffic that does not originate from these addresses.

Furthermore, we use these ranges for the nework policy exercise. Check the [yaml](../kubernetes/solutions/network_policy_ingress.yaml) file and adapt it, if necessary.

### Setup a docker registry (~1 day before course starts)
For the docker exercises you need a private docker registry. Participants will upload their custom images to it during the course. Recommendation is to spin up a registry without any persistence in the k8s cluster you use for the training.
In the admin folder of this repo, you find a registry folder with `install.registry.sh` script. Check the prerequisites and run the script as described [here](./registry/readme.md) to deploy a registry and make it available via an ingress.

## Sending the preparation mail to participants

You should send a 'preparation mail' to all participants about a week before the course starts. You should add the below information in your mail:

```
------- adapt & add this info
- Please follow these instructions to download a VM and prep for the course:
  <link to your forked repo>/blob/master/preparation.md
---------- end -----------
```
Technically it would be possible to run most of the exercises also with Docker on Windows/Mac and a local kubectl. However, we would recommend explicitly exclude support for this setup during the training.

## During the Course

**TODO: Describe how to get infrastructure support from Gardener team / link to DL**

### Add nodes to K8s cluster
It might happen that your cluster needs more resources to deal with all the participants pods. In order to scale the cluster up, go to the Gardener landing page and open the details view for your cluster. Switch to the `yaml`tab to view the current configuraiton.

By now, there is an 'edit' button that allows you to modify the shoot yaml (representing the desired state of your cluster). Increase `autScalerMax` for the worker group to add further nodes to the cluster (decrease it to dismantle nodes).

## After the course

- Destroy the Gardener trial cluster you used for the training
- Delete the kube config files you stored for your training at https://cc-admin.mo.sap.corp/userContent/k8s-trainings/
