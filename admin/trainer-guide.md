# Trainer Guide

## Overview

#### Course Prep steps
These are the logical steps for a trainer to prep for a course (details below):
- Get/ create a Gardener cluster for your training
- Download your trainer .kube/config from Gardener that lets you control the cluster
- On your VM, run the script to generate the kube configs for the participants
- Copy the generated configs to the config share of this course
- Print the access IDs sheet to be handed out to the participants (with their config IDs)

All artifacts / scripts / info needed as trainer is in this admin folder.
You can use the participant VM also for all work as a trainer.

## Course preparation

### K8s cluster in Gardener

- **Contact the [Cloud Curriculum K8s Trainings DevOps Team](mailto:DL_5B2CDDFFECB21162D9000010@sap.com?subject=[Docker%20and%20K8s%20fundamentals%20training]%20Request%20for%20trainings%20cluster%20-%20<DateOfYourTraining>) to get a Gardener K8s Cluster** for the training (~ 2 weeks in advance to the training), in case you want to use the Cloud Curriculum Resources in [Gardener](https://github.wdf.sap.corp/pages/kubernetes/gardener/) (incl. Cloud Curriculum Google Account).

- In case you have already a Gardener K8s cluster, you can take this cluster for the training.

  **Hint: The K8s cluster has to be a Gardener K8s cluster !**


### Create your trainer .kube/config

On your VM / machine
- Create a directory `.kube` under HOME (e.g. /home/vagrant on VM) and cd into it
- Create new file `config` and paste the kubeconfig yaml, you have got from [Cloud Curriculum K8s Trainings DevOps Team](mailto:DL_5B2CDDFFECB21162D9000010@sap.com?subject=[Docker%20and%20K8s%20fundamentals%20training]%20Request%20for%20trainings%20cluster%20-%20<DateOfYourTraining>) for your training.
- run `kubectl get nodes` - this command must complete by giving you a short list of nodes in the cluster

### Generate the kube configs for the participants

Download or clone this repo into the VM / your linux machine.

CD into `./docker-k8s-training/admin/kubecfggen` and there do `chmod 755 kubecfggen.sh`.

Now run the script `kubecfggen.sh`. Give it the number of participants/namespaces it should create (e.g. `kubecfggen.sh 10` creates 10 different namespaces for 10 participants).
- It creates a new directory with a new training ID `training-xxxxxxxx` (8 char ID) where all generated files will be.
- Generates a yaml to create all namespaces etc in the cluster and already execute / apply it. The cluster will then already be set up for the participants.
- Generates the kubeconfig files for the participants in the subdir for the training
- Packages all files for this training into a tar.

**Please note, the script creates not only the namespaces. It also deploys a ResourceQuota & LimitRange to each namespace.**
With this abuse of the training cluster should become harder. The ResourceQuota limits the number of pods accepted by each namespace to 15. Any particpant trying to scale a deployment to a hundred pods or more will not harm other participants. The LimitRange assigns default values for memory and CPU requested by a pod. It also give a default limit. If a pod does not specify any of these it will inherit the defaults. In other terms, by specifying a cpu/memory request & limit, the defaults can be overwritten.

### Copy the configs to the share

Upload the tar file using this Jenkins job: https://cc-admin.mo.sap.corp/view/K8s/job/upload-k8s-training-namespaces/

Participants will download 'their config' using the trainings and participant ID.


### Print the participant config codes sheet

Print the file that was generated by the `kubecfggen` run that contains the trainings ID and config codes for each participant. Cut the page at the lines so that you can hand out each code to one participant.

## Setup you up for the training

### Fork the training repo and clone it
Fork the central [training repo](https://github.wdf.sap.corp/slvi/docker-k8s-training) into your account or organization and continue to work from there. This way you will be able to adapt the training to your needs & environment.

Clone your forked repo to your VM. There are demo scripts/files for the container, docker and kubernetes parts.

### Check the (ingress) URLs
Gardener deploys an ingress controller to each cluster and allows you to register custom URLs to a specific subdomain. Since the subdomain contains the name of the Gardener project as well as the cluster, you have to adapt the ingress resources to match with your setup.

Changes are neccessary to:
* [sock-shop](../kubernetes/demo/00_sock-shop.yaml)
* [simple ingress with tls](../kubernetes/demo/09_tls_ingress.yaml)
* [fanout & virtual host ingress](../kubernetes/demo/09_fanout_and_virtual_host_ingress.yaml)

The URL pattern looks like this: `[custom-endpoint].ingress.[cluster-name].[project-name].shoot.canary.k8s-hana.ondemand.com`

### Check IP address ranges
Most likely, the Gardener cluster runs on SAP external infrastructure like AWS or GCP. To make our setup a bit more secure, we/[Cloud Curriculum K8s Trainings DevOps Team](mailto:DL_5B2CDDFFECB21162D9000010@sap.com?subject=[Docker%20and%20K8s%20fundamentals%20training]%20Request%20for%20trainings%20cluster%20-%20<DateOfYourTraining>) have limited the access to whatever you expose in the cluster to traffic originating from the SAP network at your training location. Therefor we have configured the firewall rules to block traffic, that does not originate from these addresses.

Furthermore, while the training these ranges will be used for the nework policy exercise. Check the yaml files in the [demo]((../kubernetes/demo/11_network_policy_ingress.yaml)) and [solutions]((../kubernetes/solutions/08_network_policy_ingress.yaml)) folder and adapt it, if necessary.

### Setup a docker registry (~1 day before course starts)
For the docker exercises you need a private docker registry. Participants will upload their custom images to it during the course. Recommendation is to spin up a registry without any persistence in the k8s cluster you use for the training.
In the admin folder of this repo, you find a registry folder with `install.registry.sh` script. Check the prerequisites and run the script as described [here](./registry/readme.md) to deploy a registry and make it available via an ingress.

Additionally, you have to update the URL for the registry in the exercise & solution:
* [exercise 4 - images](../docker/Exercise%204%20-%20Images.md)
* [exercise 5 - dockerfiles part 1](../docker/Exercise%205%20-%20Dockerfiles%20Part%201.md)
* [solution to exercise 4](../docker/solutions/Solution%20to%20Exercise%204%20-%20Images.md)

## Sending the preparation mail to participants

You should send a 'preparation mail' to all participants about a week before the course starts. You should add the below information in your mail:

```
------- adapt & add this info
- Please follow these instructions to download a VM and prep for the course:
  <link to your forked repo>/blob/master/preparation.md
---------- end -----------
```
Technically it would be possible to run most of the exercises also with Docker on Windows/Mac and a local kubectl. However, we would recommend explicitly exclude support for this setup during the training.

## During the Course

**TODO: Describe how to get infrastructure support from Gardener team / link to DL**

### Add nodes to K8s cluster
It might happen that your cluster needs more resources to deal with all the participants pods. In order to scale the cluster up, go to the Gardener landing page and open the details view for your cluster. Switch to the `yaml`tab to view the current configuraiton.

By now, there is an 'edit' button that allows you to modify the shoot yaml (representing the desired state of your cluster). Increase `autScalerMax` for the worker group to add further nodes to the cluster (decrease it to dismantle nodes).

## After the course

- Destroy the Gardener trial cluster you used for the training
- Delete the kube config files you stored for your training at https://cc-admin.mo.sap.corp/userContent/k8s-trainings/
